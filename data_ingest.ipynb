{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('MalDroid_feature_engineering': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6df8f70e17f22c8259d4d2a30cfb8ccb378ae2ffe8034be92b64d9d6528b27db"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# MalDroid Data Ingest\n",
    "This notebook handles the retrieval of MalDroid malware sample analysis (sample_for_analysis.apk.json) files from the MalDroid repo (http://205.174.165.80/CICDataset/MalDroid-2020/Dataset/Capturing_logs/). \n",
    "## Process\n",
    "1. Take the URIs of the .tar.gz files for each sample from MalDroid_ref_raw.csv, extract them to .tar and then to a directory *malware class*/*hash*\n",
    "2. Check to ensure the sample_for_analysis.apk.json file does not throw an error when opening. If yes, directory will be deleted and script will move to next sample\n",
    "3. Move the sample_for_analysis.apk.json file from the *malware class*/*hash*/sample_for_analysis.apk subdirectory to under *malware class*/*hash*/ and delete the subdirectory"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import tarfile\n",
    "import os\n",
    "import urllib.request\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MalDroid_ref_raw.csv') as ref_raw_path:\n",
    "    ref_raw = pd.read_csv(ref_raw_path)\n",
    "ref_raw = ref_raw[['hash', 'URI', 'malware_class']]\n",
    "ref_raw = ref_raw.drop([13076])\n",
    "# Drops final row; does not contain a sample due to parsing issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_hashes = ['0ac36a24aa3dd7e8bd7f009ab6115481812ed053c8b81967b0796a8d2f098b73', '0c41904e61ca30362129e4b7f460b2d8b5b4319de24f497b0dbdfbd64ec0f87a', '0cceea84886d862a703264074ace86a76ec8218c10789929b28352feab0d3267', '0ec63150ec195601eaaf3a42330fe03f9ea97b123ccbc728ef883271c41f8dc3', '00847524ec1e69b2cdd53205cd9725295e87094eeed1567b3efb12191ded24d2', '0669dccf3a9a08ba5d148aed4568c6a15f65075d913243f160b4c5c5ab31fc61', '082b102aaab4354b7b003a6fe5b21274582b0ed49441351a4a3f8a23012b55a5', '1d06256e8e1b7b90b242bebc323a5ef2bbbc71e72185216c3f39462c4bcb71c7', '1da5fadcaa815d9619353b8bf1bf4646c47eabfbc154d5dc7941adc1795b04b6', '2BB5E30C62E2049ADE758CF0375367B02732CE24B4C56BB234B4C4DBA3760089', '2c9fd7881e1822b92639ef3e011e64d87784d23ac05876d3fd1cec0238d1c46d', '2d62d2e6c3ec431d36ac449c0c062eee6d98b3cdac246316bb2d2622a464b26c', '2d351ee5139813d65b0f10c6fb40f9786e6ca91163e3dd2150ad4ded51ce4082', '3acbca1fb0e82db03483c8e0fbb3978c287444162e7278d2c65ea2633067087a', '3c50d8354bf9f52f3b14930599ed5a59152d83772a9b8e4377c8e0d1b73121f7', '3e0b445a1d2e33997ce78f94d62f01b5bccd6dd2b351336e567a6aac370a0b7f','3fcf12e1546a2f6b494ad42b6b699e27c4501ee662363d39ee41fd7559ac7b80','4a595d6ad083a662076b3907bcc2f5c508d63e2a7d3c0c12b4ccab98870557fd','4ab2d0bee49938748d4abf357ed2185b19dc2984fe679c0c162b0064ccb490f3','4b904ba542637bade7ff105c4e6e617b57cb1e5fd70f586f439794424f52ba40','4ce2c46fd9d88b2a2552eda6f4afc4c7e19043909fd92a294dcad198ff85cbc4', '5ace49f9f1a70b915a7e469289558c303f51ceeabf9ed6bdb5dc6818743a64ce', '5ad048ce9aeabd62088de2e8038f1540762049d64749e3a953928c2dc88e7922', '5b741e527f86eca88b64f9f64691e903110f15db77b3947a067ee1a2c44e6403', '5cbdc05183fb0ce11248ead0c4a5de031cc724171360b38214a4b3facf58ce7d', '6a59cdfefdc77efe385002e13b4dfb0595020c506c06fb0261e0be911479792e', '6a37609938daf3c7d139ef7f4222024054e18466ad752e771b26b01d36e6d8fb', '6b869cb1e71098dc70359ef3770dd0394979d50faf0ef7f955a9b83958d472db', '6cae32799b7ef805a72c575a2473d03488e2daaac7ea6906237bbd1ed74f2b55', '6dded5a4e6457fee955020998ccf176f7175d016d8f504aff32e798ec52f94f3', '6e932aecef61e61a71345a4a6bdc033aac4483d9eefb0b9f2ce7df1352ae3f5a', '7d05b21cc30b212b6e9814b3bdddf775ae8e410f31bd2d5c59355f39eb05b8c4', '7f96d56aa3bfdc3c1cefa1f024e32be3a74834bfcbac39c5fd7449bc9e8629fc', '8b9abb1eb86416332d4946fd76cdbf63b27d07f3f11fa920c2192cc16de84d36', '8b9adcd8534e45cef0f4749efc969c0988da969a2f12e60530d7403c99bf9783', '9a093cfbf7b815ae2f85796a34dfe436aeb8723027b9ba3650f0d7d5b9e5a916', '9d9647b0d4629f0755159121b2b3af5ea16236570cf0318cbe0a13d4e81b0ce8', '13b91b96b84d98452fbc1bf26554b7e5abd725bb7513f4ab59dec3245ceedfb7', '15ff51b59bf8f781b78e7f4c843b2abad6a0ab5dcd70f97315534e2b7bc0e090', '22e18b1f1e0a533cf1adbb3103b317db0d11a01f223ee1dd9bae979a2dd64151','23d9c8cca11abe2cfac4a3efd8b3883edff0eab159dfcb709d7e8f13dd3c94e1','25bb120ce291909288a13353e5e46ba9dbf4d1551346f999c3ffc7e5d5372eeb','25be589140f73949124f08759ab5bb57b126396f1401e3bfbfdc5e5c056e0d03','25c4692b0a781878087e909c34447673af41ed27fd8b768db7af84c65c5781b1','31a2566adae3689916a6405b7595f170333f6bf538167d560f3b98332df45cf2','31f6421d8e2e8d11b0e9cad08508a6354e88f5b80839da61fe75001a65ad58a8','32fe5a7358767ae5d904f551881011b7af6bc21383d58e333d397f6739603eda','38a5e1e169f3f94c675700ab8371171134f114181633532df225f99c11f7de4b','38f1d67ca112bbe4caa649e5a1d1bd21c3e04c615e1ad20cd473863301f4d4a2','45e15d928f4697147cd926bd8116538a9d29c1b47c16d39c473fdc1000738493','50a426d14ecf3aa938c637eccafbe75db04c80be43950973a79acc1bfb069d90','51ee27309fdca0451da2273390e8ea491db79f3df25bd2f563fc152b27de7689','55d417e85444f487b6844de9e1c1a0fbe2d45c2ead79b759b772e8c67362a9c7','57d5f79200f1c0f07401a8ca61a2cec66f3c6587c00b37b00e2bf221134b7d3b','59c2ba5b9b47a6c0df0e2a54b83f38d943419b7fdec6d37797fce8961a549458','69f881fee4b71287c2a285b994687d6f632589837b7c84de81a394f6d3d36756','70b8fec3d5fec7e13340350bd9209ca9b04d65841cc76b87aadd8e8b7a7bf85f','87def242def82c92704cb080fb9d32aeabfdf75290740bcd9d5db39e1d60b846','88baf90657a2fbe9abdca7840317cb8bd3b51b14ad87edfaab1b60e2c799d6d4','88c2a9d866639e84ebe9659c09db73b56eb2dfc1144475265e6920de6bebaed8','89b3095cfeac18bada832c7c0197ad4d3a420312d64839c1e21daa092da1c1bb','97f2a0da04e08671c00e31347997e85c195a8e9e66dc8bcec43055491929579b','126b346b85a96b3fec082aba092c11d37f481ef6ee40f76de9b1e9df89700c96','242a0048497bcbdeb4d1a5a43df08e492bfd42b0b85ff63b2c2a49ad5ea50829','467fbfd9b6cb258df0abdef8fce67a41b6f6b674264dccb514c1255784985bad','523ada03e2bae6ef3c079cda4bafef6201779d2ba2c01d36525c1112a30768e0','545a6714759d4133ca2b91441823da69e763eb39d4bf2304ce89a40bade0a0ea','652a7e2e53adb6a33ea5141ffdd8409ba09761a7cc72166c906c1a22fa1fc72b','660f6b9c214c5dae903433f4bce907a15e6d6b5f9a54d15f1505d68bc1e8a07e','717aea92b781b76396f45f345752ff82c62ebfce78f18f29b6919584b1eb445a','759b0e1ff925abddc1ba22bd8e9d5a540dc0e698baeef2bc1522ced4162fc8f4']\n",
    "\n",
    "large_hashes = ['0ccf9cfae60602b20c679ad8d56cc14f94ebf50aed389ef9db8a86e717ed76ea', '0f18d0cf80f7619d17142110eadbfe1ad01bc5936f275d666c454234241ca382', '03c78d58f22b4ebe6bb92735d19c869e57d10ed3071644c1a429170e7c9f3d51', '048449f839bfa7afc61aed035ba870aff254b7534c8444cbb701e31ec6d47f24', '09c70721776a3d0b345d2fbc647b363648c91b2f8f3dd0c25cf928aba4ade179',\n",
    "'1a2a6761a1279bfe9a352381dd66614b466b19aefaf17c300536be8e4be0b0c5',\n",
    "'1a2b969ba56b3d3473fe45f87a04fa9610293e2ccf687b2d1d71220b8c765077',\n",
    "'1a9a75579366f1d2dbeaa6d2423819d874537973815778eae3debef47da08a1d',\n",
    "'1c31d50db2aca2c03836e7e0cbef657e97ee8dae70758c58f89975a11fc0b6ca', '1e83a89395c3de4d2f0945e21d3fd6a7324538c0aa613836cfbe212c2bc1d145', '2de4216275ee614c108ab69519e97c7a9fcf50b9593557d554749165ee55a4b5', '2fbbe31be65aecfc88bf9f321f128f28280ae7dc26117a0ac2c179d9c7521d94', '5b42432aad27746f04353fdd70bd8c2d979303eaf367de28d88f6b0cb72dd9a5', '5bc23138fd301b7f293f9b4efb13d72019815d64695a6f9b694c23c33f1442b8', '6f012f1a12bec0dba7d0e23f03593d2339c1e7e8af8fcff70650c44ea72717e4', '7b5338e1e7bf8b4816b821db9ed042ed13ce4f8ebd1748ba9788b070e45bf03d', '7e5e1502c9f2db87563ac77f8e420ffe281fe0d02b6773a6f1873d88fcada4d4', '8be77cdbc0e25a1a6342544057f8fdf3839be43b313074af794df36b36f3b165','9d9cc59569aa8706d797cca4df36f689878305039cd8b41d99de3007681f814e','9f42775930835f224c2af24a924964bb7027f3f1b90548865b9801f63fa7fb2b','10f6a5912fc45c6dce219f28bd493a765081f6a01b090293b5a3b57836c762eb','27f0a1484ace19692681d3f938d161cdbb943edb2452674fb13599be71f9c665','31b2ba2f2c1fb196dd38017134b5402dde24803f764de6962f68d2c71edbabdf','34ff80271b6864e437812edeb4ff7ed465a1d359af4c2271c22e745c1c6d3a9d','49dfe143dc62ad64d62bcd33f4e771662514462788d393daeb5549fcaecdf339','52b563e039fbcbb875625f2d8bf27a491c31867c1ce37c1148a267ced9923c2a','64a77e654d5f4c183182628ef446734468068fd5f9af99be5220bb8f25036192','72e6ae9cd081f8d38488cf4077f66db0f97cef486a60eb38c593ba82db77ecd8','77c57468c9857c20c69dedec214845f6e13f53bd8ff486b58b10df7629b45a05','98bed95679d422e89d48f08b62db8103a880aa498f364b733c8a110656dc9134','213a0abc71295a8d9e2062c1758b9533717f2e6cd79c01841f768e2e8e1f6a0f','228eb3562a913b827f11b736b649bfb18ed8b6dc5422f311cfc5ea11e5dbafe0','452b25f223ac1ea7f77bc9c78fd6bf8bf444b9372a8dec111a01827ac8a0c0bd','478fda44cbe4ece2931ea0f3b244b522b9638ca55c8592756ab092e041e52e34','582de54cf4e74d2474d47514393e57f55e251586de0b5be62c5f82b6109520e0','734df9c568c7d05544ecde71aafdbcf2a882c81b23753beb6d71f2c9b2a03024','770cd9626aefe1aeffa70155068c5880963eb634895f21b5ea25ec91c494cb72']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Error extracting on hash: 1809d2294f47701969299b4eb5926fcc3fba3a6ba3bcaed36c699bd2a0792d0e\n",
      "JSON file too large on hash: 2669b8183b767c0f766a62c5e39e8414befbaa628bd1201630242ede8ed8ef9d\n",
      "Error extracting on hash: 5727df58b9636fd66130772ce5baf586635f1e7b8706ffb76b837143c35e4158\n",
      "Error extracting on hash: 6218f751b9e15cebc36a30ceeeb70b6512ae22e3f04c1acb52eab2c505de1d8a\n",
      "Error extracting on hash: 8143d45cb4edf607996e7889ce8f94827b93c16ca5ff18ca007bbbbffdbb0bb7\n",
      "JSON file too large on hash: 9985b52ce2fb592fc103ae907ba809d4d5c8546a19d5499d07d1f8fca179ae4f\n",
      "JSON file too large on hash: 10425aea7317cc1da95a232189e653b2cc6876e23cfce45d6215c6c86f223eb9\n",
      "JSON file too large on hash: 12952e8099be21de583fd1cac6b90bc4dd012f4b2b5c157edb318b34c07c1995\n",
      "JSON file too large on hash: 35206eaf2cdf0b592b526a698046b2326086b723fc35d6489d86802efed37370\n",
      "Error extracting on hash: 42493d53740704f319676a19e669a3ff1b47b2138d555090036b310aefe9a51f\n",
      "JSON file too large on hash: 77227f1c25d32b0fedcc46843ae6744cfd7ca01f1e5e51fe881008d2b8f29609\n",
      "Error extracting on hash: 96260a93c9809d417dacaf905ee26042fd43edacc3bc418e75d10469649626e8\n",
      "Error extracting on hash: 1101724b9c92cfebd793bdc1501a8aedae8ec84cb499e35b115fba98076be993\n",
      "Error extracting on hash: 4902335bfb5d73964fe57ddd76a9a0f463f3aa8f4781aee985df0ce8ddcf9aaf\n",
      "JSON file too large on hash: 8051668dc4b6671da7585e30ee059438f425777efff22bc3566baa5615413add\n",
      "JSON file too large on hash: 9156068fc7c4bd78fe49be13fae7712d4047bf7d2af65846a2bb622fe9d78ccb\n",
      "Error extracting on hash: 38834157e919d084e26505d7a8e10f508319b174f9dd65c8aa82b01907323d38\n",
      "JSON file too large on hash: 141628998bf8c8cfd304341f84931f63d8301b397fee1839766579866ff08751\n",
      "Error extracting on hash: 635103617bdcb8e8b62ec719731149761d85dad1566a786bcb014128b28c2212\n",
      "Error extracting on hash: 4142741205ff02d819bca5dd47f2bb74a1254120d6fe83f6dc23d9b7c82aad05\n",
      "JSON file too large on hash: 5742909913fe0d1d2631bab4f4edff1e03ced1a333d706d3cde8309f1ccd9c27\n",
      "JSON file too large on hash: 8729845381ba51b2fde3d60d3abce0a7d9be69ca3bb6b6b66aa1f1b669f3995c\n",
      "JSON file too large on hash: a0c52d1d5d6cb108d6be2d90576d19a32b55d0e838654f6ea5fc6733212c11b7\n",
      "Error extracting on hash: a74dc326a8af162eb9b36ac6bbe48602893c9c9d94326e11917535f329da0831\n",
      "Error extracting on hash: a312cd7322c273c142c58165158b42668cd7de386659fed1038d07dc6190df16\n",
      "JSON file too large on hash: a482db7545df1008ed2d9c45999b52037da9f42db2928bc6f3d99e0ab625e003\n",
      "Error extracting on hash: a8726d22a5480651c395c88d9cc24c0cc7d8b2d2d626526454ef96daf0bcd999\n",
      "Error extracting on hash: a8765fa38aa7e1ff64af2e9c6dc864c23f156cebd058d50bb03ab21c76ada14b\n",
      "JSON file too large on hash: a9925db1a5529a35c7566246f8b82181c75a3017a971268285d0cf67817f3ca2\n",
      "JSON file too large on hash: a8526575a09d170f6bc89c66cfdcc53816bac03b470ae21a51825e75e02e1695\n",
      "JSON file too large on hash: a19903990c9dbc38fcaaa3db476cf175caf09169fe9fc4988992fac4258ff030\n",
      "JSON file too large on hash: acacab580a1f6c54798174422d51eb9392a744ddb26fe07c9b6e99a1811dd6e0\n",
      "Error extracting on hash: ad7e1cece350d886feb4d37c0a5c82966e5577d6ce61f1977f21fe8c27fbf13e\n",
      "Error extracting on hash: ae0bc1b2ef2b18182b5f9d889d4aa270144ab95e10ef5957e936ba67ea4b024e\n",
      "JSON file too large on hash: aefbba5e49c7d9dd95bd1cf1b51e19f526e9f8ba55c10d16477bef97dbcb8a24\n",
      "JSON file too large on hash: b2a4c955131de3aef729ec64a997c2b8552b780f14672cfd303be77d0ae394e3\n",
      "JSON file too large on hash: b3c9851ceff2d6fdb5ceccee124dc82e34cfc5e9344671abfc0a7c028afcf846\n",
      "JSON file too large on hash: b3eb2cb840d7999542fd073cb5530562f6a2f393abe0187c20415852f5fd1855\n",
      "JSON file too large on hash: b4b5363aca7fed33527fa82d89412d113bf9dc7e0207946533c07fb2b98f8e5b\n",
      "Error extracting on hash: b6b57f6bca0507f15a86f168bbbda1fcc933203a4f960002fafa48281c0f8b99\n",
      "JSON file too large on hash: b8cf2e3cc7c40d693ccb1deba2111327d55317b4d59ff4511d9b19367e956586\n",
      "Error extracting on hash: b100add772e3b003b661230d9d581eb3450eae516c2f2e345a99ada99fc653ac\n",
      "JSON file too large on hash: b186ff2e168c31f76141cbc32c075397a48080b101617657db002b9cb577deab\n",
      "Error extracting on hash: bae8549d3c36bdd38843557e0901baeeb12cc3f22bbeb51986665c4762bc0ca4\n",
      "JSON file too large on hash: bbe98778f159dea179f657b2d0e1723ec4aa6bfdc838db77f52a016b595d47ea\n",
      "Error extracting on hash: bd0f934260fe4392779b0ea19ebaa80f31fd342d574474dc7a296fb7c5a7469d\n",
      "Error extracting on hash: c04c5b1876ea06be4420c7e302478b1553f82d320d0bcac035c2daa89bbb03f9\n",
      "Error extracting on hash: c2c1d2689d5157138144cd7765b180c74ae92fdb58e5c87e615aa9e71c05d1e3\n",
      "JSON file too large on hash: c3ab7f5f0d1c84e7a9cd8d22cbcaec76b51687f5689941900100f9ebd78720ac\n",
      "Error extracting on hash: c5c508fd88d058f5e2b3abc2a066c52c1fafb148f27000c47da859945f771512\n",
      "JSON file too large on hash: c7c653214480136303f1bbb443e0025d64332cc98da8441ecbe66c1092cb508f\n",
      "Error extracting on hash: c7e2fce44de20e1c2644885814dff4dac4d4fe288fbea8f23cedb1025830595c\n",
      "Error extracting on hash: c8beb967c2359c90f80badef6f14cc4c52b53fc8ebf3f6c1a1f06faa1e6f4dd4\n",
      "JSON file too large on hash: c9f2c62aa15c969786f66248ad719e26ba0e7f554590a75734adf41c72545a1d\n",
      "Error extracting on hash: c2906b49327d9d11d7d7f30e08c99e4479b9acb1c886a437ce4cf5283eef021d\n",
      "JSON file too large on hash: c15952d4ad7028e8bde2a312c123060bdb9c250b89566dc8e8752336f01b60b9\n",
      "JSON file too large on hash: c46887c9f24d002b013f9726cb4c74dfd60a6299ca7be1828b1d9e947d19fe54\n",
      "Error extracting on hash: c96029c4f9777c9d521249ee1ac27f75c2350614c361469d0c7b3f8124da3e14\n",
      "JSON file too large on hash: c152360c182ee85f7fcdddf5bfbcdb56c6f412994ebd6262b90c41f3df993ec2\n",
      "Error extracting on hash: cd770b80a8c112adcafec9bf591f34c73c4344848e1e1bd1f6be09d6e14aa672\n",
      "Error extracting on hash: cee4e40403f1658e985de9d812d053fc8bd233d88178e0d9075d175321e008d4\n",
      "JSON file too large on hash: cf479157bfbae96a75799ed23ea0c3fe2ff7364fd75856ff295c0fe99cc0ab2d\n",
      "Error extracting on hash: d0d6780f80e78bc299eb0850a5d4e4b6c48d33267c8df6512897fa15f869b428\n",
      "JSON file too large on hash: d099ca05db3a03a6de78f3c3fee7ad236e3c2919f79a5d526be23a541430f05d\n",
      "Error extracting on hash: d2f5465b1815f8399c156c30ecb10ea9d0785f7b3b56e15d339a54500e457751\n",
      "Error extracting on hash: d5e46f4a3812a6cc880d5e55e60f8568dd236867b8788a5333d3c9ddad9885ef\n",
      "JSON file too large on hash: d5ea9261bf0c718798f027f37502ac417afac1b92ac8460446f293c9e5831bd8\n",
      "Error extracting on hash: d6f8b8cd178d207ea1cbd0ba4b0f4c9a8a85c539759102086e7fa2868b8677ae\n",
      "JSON file too large on hash: d7b9ea9646d490f7586d14cb832015a32f0699342bd4bb3f5d2f4bcea979b256\n",
      "Error extracting on hash: d42c56b1e78e6ea5cb6e6363acb05cdec2ebaf22b419aafa47be6b796ceeffb9\n",
      "JSON file too large on hash: d52926be5bc05c304c544b90d547bcd517c6209508bf14c3a173a7da083ce851\n",
      "Error extracting on hash: d3183051ecabc6da4a40bd3a8e63ab6bd0272e906958c5c064c048ce4a02d416\n",
      "JSON file too large on hash: dc2bec9abc184b7fe88ee9950d53c5d36cb58734dc3182566777e1b039656251\n",
      "JSON file too large on hash: dc8685e99ff356b9d06a7f76c02f50fd06569455cfa15016b340378f367c831d\n",
      "Error extracting on hash: ddd8be38bd0aebf3fe7cc7c53f8e629f0a5f954436bb62c1e6638791da2f8fc6\n"
     ]
    }
   ],
   "source": [
    "last_hash = '946fa4e1f5df0f010a23fcc6bfa756ae3dffdc485f61c0639331f4e4a0008d0f'\n",
    "last_hash = last_hash.lower()\n",
    "\n",
    "# prev_index = ref_raw['hash'].loc[lambda x: x==last_hash].index\n",
    "ref_raw = ref_raw.iloc[707:]\n",
    "\n",
    "def ingest_loop(sample):\n",
    "    last_hash = sample[0]\n",
    "    if '.tar.gz' in sample[1]:\n",
    "        base_path = sample[2].lower() + '/' + sample[0]\n",
    "        try:\n",
    "            temp_file = urllib.request.urlretrieve(sample[1], filename=None)[0]\n",
    "        except:\n",
    "            print('Error loading URL on hash: ' + sample[0])\n",
    "            issue_hashes.append(sample[0])\n",
    "            return\n",
    "        try:\n",
    "            file = tarfile.open(temp_file)\n",
    "            file.extractall(base_path)\n",
    "            file.close()\n",
    "        except:\n",
    "            print('Error extracting on hash: ' + sample[0])\n",
    "            issue_hashes.append(sample[0])\n",
    "            try:\n",
    "                shutil.rmtree(base_path)\n",
    "            except:\n",
    "                pass\n",
    "            return\n",
    "        default_path = open(base_path + '/sample_for_analysis.apk/sample_for_analysis.apk.json')\n",
    "        try:\n",
    "            json.load(default_path)\n",
    "            default_path.close()\n",
    "        except:\n",
    "            print('Error loading JSON on hash: ' + sample[0])\n",
    "            issue_hashes.append(sample[0])\n",
    "            default_path.close()\n",
    "            return\n",
    "        json_size = os.stat(base_path + '/sample_for_analysis.apk/sample_for_analysis.apk.json').st_size\n",
    "        if json_size >= 100000000:\n",
    "            # GitHub will not host files larger than 100 MB, this removes and logs these files for compatability\n",
    "            print('JSON file too large on hash: ' + sample[0])\n",
    "            large_hashes.append(sample[0])\n",
    "            shutil.rmtree(base_path)\n",
    "            return\n",
    "        shutil.move(base_path + '/sample_for_analysis.apk/sample_for_analysis.apk.json', base_path + '/sample_for_analysis.apk.json')\n",
    "        shutil.rmtree(base_path + '/sample_for_analysis.apk')\n",
    "\n",
    "ref_raw.apply(lambda x: ingest_loop(x.to_numpy()), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_df = pd.DataFrame(issue_hashes, columns = ['hash'])\n",
    "with open('issue_hashes.csv', 'w') as issue_write:\n",
    "    issue_df.to_csv(issue_write)\n",
    "\n",
    "large_df = pd.DataFrame(large_hashes, columns = ['hash'])\n",
    "with open('large_hashes.csv', 'w') as large_write:\n",
    "    large_df.to_csv(large_write)\n",
    "\n",
    "with open('last_hash_processed.txt', 'w') as resume_write:\n",
    "    resume_write.write(last_hash)"
   ]
  }
 ]
}